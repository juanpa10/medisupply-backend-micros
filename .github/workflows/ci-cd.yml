name: Micros CI/CD → ECR + ECS (auto)

on:
  push:
    branches: ["main"]
  workflow_dispatch: {}

# Variables (Settings ➜ Actions ➜ Variables)
#  - AWS_REGION: us-east-1
#  - ECR_REPOSITORY: medisupply
#  - CLUSTER: medisupply
#  - ALB_NAME: portal-web-alb
#  - ECS_SG_ID: sg-xxxxxxxx   # SG de TAREAS ECS (no el del ALB)
env:
  AWS_REGION: ${{ vars.AWS_REGION }}
  ECR_REPOSITORY: ${{ vars.ECR_REPOSITORY }}
  CLUSTER: ${{ vars.CLUSTER }}
  ALB_NAME: ${{ vars.ALB_NAME }}
  ECS_SG_ID: ${{ vars.ECS_SG_ID }}

jobs:
  discover:
    name: Discover microservices
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.mk.outputs.matrix }}
    steps:
      - uses: actions/checkout@v4

      - name: Show repo tree (debug)
        run: |
          pwd
          ls -la
          echo "---- first level ----"
          find . -maxdepth 1 -type d -not -path './.git' -print
          echo "---- dockerfiles (any depth) ----"
          git ls-files '*Dockerfile' || true

      - name: Build matrix scanning any subfolder with Dockerfile + service.json
        id: mk
        run: |
          set -e
          arr='[]'
          # Recorre TODOS los Dockerfile del repo (excluye .github)
          while IFS= read -r dockerfile; do
            dir=$(dirname "$dockerfile")
            case "$dir" in ./.github/*) continue ;; esac
            if [ -f "$dir/service.json" ]; then
              name=$(jq -r '.name' "$dir/service.json")
              arr=$(jq --arg n "$name" --arg c "$dir" '. + [{"name":$n,"context":$c}]' <<<"$arr")
              echo "✔ Found service: $name at $dir"
            else
              echo "⚠️  $dir tiene Dockerfile pero NO service.json (se ignora)"
            fi
          done < <(git ls-files '*Dockerfile')
          echo "Servicios detectados:"; echo "$arr" | jq .
          echo "matrix={\"include\":$(jq -c <<<"$arr")}" >> "$GITHUB_OUTPUT"

  test:
    name: Unit tests (pytest) per micro
    needs: discover
    if: ${{ needs.discover.outputs.matrix != '' && needs.discover.outputs.matrix != '{"include":[]}' }}
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix: ${{ fromJson(needs.discover.outputs.matrix) }}
    steps:
      - uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install deps if requirements.txt exists
        working-directory: ${{ matrix.context }}
        run: |
          if [ -f requirements.txt ]; then
            python -m pip install --upgrade pip
            pip install -r requirements.txt
          else
            echo "No requirements.txt in $PWD — skipping deps install."
          fi
          
      - name: Run tests with coverage
        working-directory: ${{ matrix.context }}
        run: |
          if [ -d tests ] || ls -1 *test*.py test_*.py 2>/dev/null | grep -q .; then
            pip install pytest-cov
            pytest --cov=. --cov-report=term-missing -q
          else
            echo "No tests found — skipping coverage."
          fi    

  build_push:
    name: Build & Push to ECR
    needs: [discover, test]
    if: ${{ needs.discover.outputs.matrix != '' && needs.discover.outputs.matrix != '{"include":[]}' }}
    runs-on: ubuntu-latest
    permissions: { id-token: write, contents: read }
    strategy:
      fail-fast: false
      matrix: ${{ fromJson(needs.discover.outputs.matrix) }}
    steps:
      - uses: actions/checkout@v4

      - name: Configure AWS credentials (OIDC)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.ROLE_TO_ASSUME }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Login to Amazon ECR
        uses: aws-actions/amazon-ecr-login@v2

      - name: Docker metadata (${{ matrix.name }})
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ secrets.AWS_ACCOUNT_ID }}.dkr.ecr.${{ env.AWS_REGION }}.amazonaws.com/${{ env.ECR_REPOSITORY }}
          tags: |
            type=sha,prefix=${{ matrix.name }}-
            type=ref,event=branch,prefix=${{ matrix.name }}-
            type=raw,value=${{ matrix.name }}-latest,enable={{is_default_branch}}

      - name: Set up Buildx
        uses: docker/setup-buildx-action@v3

      - name: Build & Push ${{ matrix.name }}
        uses: docker/build-push-action@v6
        with:
          context: ${{ matrix.context }}
          push: true
          platforms: linux/amd64
          provenance: false
          sbom: false
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max

  deploy:
    name: Deploy to ECS/ALB
    needs: [discover, build_push]
    if: ${{ needs.discover.outputs.matrix != '' && needs.discover.outputs.matrix != '{"include":[]}' }}
    runs-on: ubuntu-latest
    permissions: { id-token: write, contents: read }
    steps:
      - uses: actions/checkout@v4

      - name: Configure AWS credentials (OIDC)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.ROLE_TO_ASSUME }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Deploy each micro (task def + service + ALB rule)
        env:
          ACCOUNT_ID: ${{ secrets.AWS_ACCOUNT_ID }}
        run: |
          set -e

          # --- ALB, Listener y VPC ---
          alb_arn=$(aws elbv2 describe-load-balancers \
            --names "${ALB_NAME}" \
            --query 'LoadBalancers[0].LoadBalancerArn' \
            --output text --region "${AWS_REGION}")

          listener_arn=$(aws elbv2 describe-listeners \
            --load-balancer-arn "$alb_arn" \
            --query 'Listeners[?Port==`80`].ListenerArn' \
            --output text --region "${AWS_REGION}")

          vpc_id=$(aws elbv2 describe-load-balancers \
            --load-balancer-arns "$alb_arn" \
            --query 'LoadBalancers[0].VpcId' \
            --output text --region "${AWS_REGION}")

          # --- Subnets públicas (robusto) ---
          readarray -t subnets_arr < <(
            aws ec2 describe-subnets \
              --filters "Name=vpc-id,Values=${vpc_id}" "Name=map-public-ip-on-launch,Values=true" \
              --query 'Subnets[].SubnetId' \
              --output text --region "${AWS_REGION}" | tr '\t' '\n' | sed '/^$/d'
          )
          if [ ${#subnets_arr[@]} -eq 0 ]; then
            readarray -t subnets_arr < <(
              aws ec2 describe-subnets \
                --filters "Name=vpc-id,Values=${vpc_id}" \
                --query 'Subnets[].SubnetId' \
                --output text --region "${AWS_REGION}" | tr '\t' '\n' | sed '/^$/d'
            )
          fi
          if [ ${#subnets_arr[@]} -eq 0 ]; then
            echo "❌ No se encontraron Subnets en la VPC ${vpc_id}"; exit 1
          fi
          subnets_csv=$(IFS=,; echo "${subnets_arr[*]}")
          netconf="awsvpcConfiguration={subnets=[${subnets_csv}],securityGroups=[${ECS_SG_ID}],assignPublicIp=ENABLED}"
          echo "ℹ️  Subnets detectadas: ${subnets_csv}"
          echo "ℹ️  Network config: $netconf"

          # --- Recorre servicios (misma lógica que discover) ---
          while IFS= read -r dockerfile; do
            dir=$(dirname "$dockerfile")
            case "$dir" in ./.github/*) continue ;; esac
            [ -f "$dir/service.json" ] || continue

            name=$(jq -r '.name' "$dir/service.json")
            containerPort=$(jq -r '.containerPort' "$dir/service.json")
            pathPrefix=$(jq -r '.pathPrefix' "$dir/service.json")
            healthPath=$(jq -r '.healthPath' "$dir/service.json")
            cpu=$(jq -r '.cpu' "$dir/service.json")
            memory=$(jq -r '.memory' "$dir/service.json")
            desired=$(jq -r '.desiredCount' "$dir/service.json")

            image="${ACCOUNT_ID}.dkr.ecr.${AWS_REGION}.amazonaws.com/${ECR_REPOSITORY}:${name}-latest"
            log_group="/ecs/${name}"
            tg_name="${name}-tg"
            svc_name="${name}-svc"

            echo "==> Deploy ${name} | port=${containerPort} | path=${pathPrefix}"

            # Log group (idempotente)
            aws logs create-log-group --log-group-name "$log_group" --region "${AWS_REGION}" 2>/dev/null || true

            # Target group (crear si no existe)
            tg_arn=$(aws elbv2 describe-target-groups --names "$tg_name" --query 'TargetGroups[0].TargetGroupArn' --output text --region "${AWS_REGION}" 2>/dev/null || true)
            if [ "$tg_arn" = "None" ] || [ -z "$tg_arn" ]; then
              tg_arn=$(aws elbv2 create-target-group \
                --name "$tg_name" \
                --protocol HTTP \
                --port ${containerPort} \
                --vpc-id "$vpc_id" \
                --target-type ip \
                --health-check-path "${healthPath}" \
                --health-check-port traffic-port \
                --matcher HttpCode=200-399 \
                --query 'TargetGroups[0].TargetGroupArn' \
                --output text --region "${AWS_REGION}")
            fi

            # Regla de ALB (si pathPrefix no es vacío)
            if [ -n "$pathPrefix" ] && [ "$pathPrefix" != "null" ]; then
              existing_rule=$(aws elbv2 describe-rules --listener-arn "$listener_arn" \
                --query "Rules[?contains(join('', Conditions[?Field=='path-pattern'].Values[]),'${pathPrefix%*}')] | [0].RuleArn" \
                --output text --region "${AWS_REGION}" 2>/dev/null || true)
              if [ "$existing_rule" = "None" ] || [ -z "$existing_rule" ]; then
                prio=200
                while aws elbv2 describe-rules --listener-arn "$listener_arn" --query "Rules[?Priority=='${prio}']" --output text --region "${AWS_REGION}" | grep -q .; do
                  prio=$((prio+1))
                done
                aws elbv2 create-rule \
                  --listener-arn "$listener_arn" \
                  --priority $prio \
                  --conditions Field=path-pattern,Values="${pathPrefix}" \
                  --actions Type=forward,TargetGroupArn="$tg_arn" \
                  --region "${AWS_REGION}" >/dev/null
              fi
            fi

            # Task Definition con jq (sin here-docs)
            td_file=$(mktemp)
            jq -n \
              --arg family "$name" \
              --arg cpu "$cpu" \
              --arg memory "$memory" \
              --arg execRole "arn:aws:iam::${ACCOUNT_ID}:role/ecsTaskExecutionRole" \
              --arg cname "$name" \
              --arg image "$image" \
              --arg log_group "$log_group" \
              --arg region "$AWS_REGION" \
              --arg stream "$name" \
              --argjson cport ${containerPort} \
            '{
              family: $family,
              networkMode: "awsvpc",
              requiresCompatibilities: ["FARGATE"],
              cpu: $cpu,
              memory: $memory,
              executionRoleArn: $execRole,
              containerDefinitions: [{
                name: $cname,
                image: $image,
                portMappings: [{ containerPort: $cport, protocol: "tcp" }],
                essential: true,
                logConfiguration: {
                  logDriver: "awslogs",
                  options: {
                    "awslogs-group": $log_group,
                    "awslogs-region": $region,
                    "awslogs-stream-prefix": $stream
                  }
                }
              }]
            }' > "$td_file"

            rev=$(aws ecs register-task-definition \
              --cli-input-json file://"$td_file" \
              --query 'taskDefinition.revision' --output text --region "${AWS_REGION}")
            rm -f "$td_file"

            # Crear/actualizar servicio ECS
            svc_status=$(aws ecs describe-services --cluster "${CLUSTER}" --services "${svc_name}" --query 'services[0].status' --output text --region "${AWS_REGION}" 2>/dev/null || true)
            if [ "$svc_status" = "None" ] || [ -z "$svc_status" ]; then
              aws ecs create-service \
                --cluster "${CLUSTER}" \
                --service-name "${svc_name}" \
                --task-definition "${name}:${rev}" \
                --desired-count ${desired} \
                --launch-type FARGATE \
                --network-configuration "$netconf" \
                --load-balancers "targetGroupArn=${tg_arn},containerName=${name},containerPort=${containerPort}" \
                --region "${AWS_REGION}" >/dev/null
            else
              aws ecs update-service \
                --cluster "${CLUSTER}" \
                --service "${svc_name}" \
                --task-definition "${name}:${rev}" \
                --desired-count ${desired} \
                --force-new-deployment \
                --region "${AWS_REGION}" >/dev/null
            fi

            echo "✔ ${name} deployed"
          done < <(git ls-files '*Dockerfile')
